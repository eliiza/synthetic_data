{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, accuracy_score\n",
    "    )\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Fraud data\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables in numeric or binary format depending on cardinality\n",
    "\n",
    "XGBoost does not accept categorical values in integer form, so we have to encode them differently. For comparison, the key values for the ExtraTrees classifier (out-of-box, with balanced weights) were Precision 1.0, Recall 0.6939. It will be interesting to see how the binary encoding changes these values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data['type_enc'] = LabelEncoder().fit_transform(fraud_data['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benc = BinaryEncoder(cols=['nameOrig', 'nameDest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
       "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
       "       'isFlaggedFraud', 'type_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = benc.fit_transform(fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 57 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            object \n",
      " 2   amount          float64\n",
      " 3   nameOrig_0      int64  \n",
      " 4   nameOrig_1      int64  \n",
      " 5   nameOrig_2      int64  \n",
      " 6   nameOrig_3      int64  \n",
      " 7   nameOrig_4      int64  \n",
      " 8   nameOrig_5      int64  \n",
      " 9   nameOrig_6      int64  \n",
      " 10  nameOrig_7      int64  \n",
      " 11  nameOrig_8      int64  \n",
      " 12  nameOrig_9      int64  \n",
      " 13  nameOrig_10     int64  \n",
      " 14  nameOrig_11     int64  \n",
      " 15  nameOrig_12     int64  \n",
      " 16  nameOrig_13     int64  \n",
      " 17  nameOrig_14     int64  \n",
      " 18  nameOrig_15     int64  \n",
      " 19  nameOrig_16     int64  \n",
      " 20  nameOrig_17     int64  \n",
      " 21  nameOrig_18     int64  \n",
      " 22  nameOrig_19     int64  \n",
      " 23  nameOrig_20     int64  \n",
      " 24  nameOrig_21     int64  \n",
      " 25  nameOrig_22     int64  \n",
      " 26  nameOrig_23     int64  \n",
      " 27  oldbalanceOrg   float64\n",
      " 28  newbalanceOrig  float64\n",
      " 29  nameDest_0      int64  \n",
      " 30  nameDest_1      int64  \n",
      " 31  nameDest_2      int64  \n",
      " 32  nameDest_3      int64  \n",
      " 33  nameDest_4      int64  \n",
      " 34  nameDest_5      int64  \n",
      " 35  nameDest_6      int64  \n",
      " 36  nameDest_7      int64  \n",
      " 37  nameDest_8      int64  \n",
      " 38  nameDest_9      int64  \n",
      " 39  nameDest_10     int64  \n",
      " 40  nameDest_11     int64  \n",
      " 41  nameDest_12     int64  \n",
      " 42  nameDest_13     int64  \n",
      " 43  nameDest_14     int64  \n",
      " 44  nameDest_15     int64  \n",
      " 45  nameDest_16     int64  \n",
      " 46  nameDest_17     int64  \n",
      " 47  nameDest_18     int64  \n",
      " 48  nameDest_19     int64  \n",
      " 49  nameDest_20     int64  \n",
      " 50  nameDest_21     int64  \n",
      " 51  nameDest_22     int64  \n",
      " 52  oldbalanceDest  float64\n",
      " 53  newbalanceDest  float64\n",
      " 54  isFraud         int64  \n",
      " 55  isFlaggedFraud  int64  \n",
      " 56  type_enc        int64  \n",
      "dtypes: float64(5), int64(51), object(1)\n",
      "memory usage: 2.7+ GB\n"
     ]
    }
   ],
   "source": [
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['step', 'amount', 'nameOrig_0', 'nameOrig_1', 'nameOrig_2',\n",
    "       'nameOrig_3', 'nameOrig_4', 'nameOrig_5', 'nameOrig_6', 'nameOrig_7',\n",
    "       'nameOrig_8', 'nameOrig_9', 'nameOrig_10', 'nameOrig_11', 'nameOrig_12',\n",
    "       'nameOrig_13', 'nameOrig_14', 'nameOrig_15', 'nameOrig_16',\n",
    "       'nameOrig_17', 'nameOrig_18', 'nameOrig_19', 'nameOrig_20',\n",
    "       'nameOrig_21', 'nameOrig_22', 'nameOrig_23', 'oldbalanceOrg',\n",
    "       'newbalanceOrig', 'nameDest_0', 'nameDest_1', 'nameDest_2',\n",
    "       'nameDest_3', 'nameDest_4', 'nameDest_5', 'nameDest_6', 'nameDest_7',\n",
    "       'nameDest_8', 'nameDest_9', 'nameDest_10', 'nameDest_11', 'nameDest_12',\n",
    "       'nameDest_13', 'nameDest_14', 'nameDest_15', 'nameDest_16',\n",
    "       'nameDest_17', 'nameDest_18', 'nameDest_19', 'nameDest_20',\n",
    "       'nameDest_21', 'nameDest_22', 'oldbalanceDest', 'newbalanceDest',\n",
    "       'type_enc']\n",
    "label_col = ['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide up training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = np.round(len(fraud_data.index) * 0.9, 0)\n",
    "train_X = fraud_data.loc[:train_length, train_cols]\n",
    "train_y = fraud_data.loc[:train_length, label_col]\n",
    "valid_X = fraud_data.loc[train_length:, train_cols]\n",
    "valid_y = fraud_data.loc[train_length:, label_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test new encoding through previously tried and new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eikegermann/anaconda3/envs/fraud_detection/lib/python3.8/site-packages/lightgbm/basic.py:1294: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['type_enc']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.24986512524084778\n",
      "Recall:  0.861317747077577\n",
      "ROC score:  0.9229647780633877\n",
      "F1 score:  0.3873588625365912\n",
      "Accuracy score:  0.9838824257931481\n"
     ]
    }
   ],
   "source": [
    "clf = lgbm.LGBMClassifier(n_estimators=1000, random_state=42, class_weight='balanced', objective='binary')\n",
    "\n",
    "clf.fit(train_X, np.ravel(train_y), categorical_feature=['type_enc'])\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:41] WARNING: /Users/travis/build/dmlc/xgboost/src/gbm/gbtree.cc:139: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "Precision:  0.9974838245866283\n",
      "Recall:  0.7372476089266737\n",
      "ROC score:  0.8686182708490013\n",
      "F1 score:  0.8478460128322639\n",
      "Accuracy score:  0.9984346071272526\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "clf.fit(train_X, np.ravel(train_y))\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eikegermann/anaconda3/envs/fraud_detection/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "ROC score:  0.5\n",
      "F1 score:  0.0\n",
      "Accuracy score:  0.994084198019055\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=250, random_state=42, class_weight='balanced')\n",
    "\n",
    "clf.fit(train_X, np.ravel(train_y))\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9974901398350663\n",
      "Recall:  0.7391073326248672\n",
      "ROC score:  0.869548132698098\n",
      "F1 score:  0.8490767587364565\n",
      "Accuracy score:  0.9984456088843904\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(random_state=42, tree_method='exact')\n",
    "\n",
    "clf.fit(train_X, np.ravel(train_y))\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the TomekLinks, RandomOverSampler and SMOTETomek. They have a good balance of precision and recall in the imbalanced library. If that doesn't do it, we might have to run a gridsearch on xgboost hyperparameters or try and concoct a new feature. Although I wonder what that is going to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "toli = TomekLinks()\n",
    "\n",
    "train_X_resampled, train_y_resampled = toli.fit_resample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:29:17] WARNING: /Users/travis/build/dmlc/xgboost/src/gbm/gbtree.cc:139: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "Precision:  0.997482919813017\n",
      "Recall:  0.7369819341126461\n",
      "ROC score:  0.8684854334419875\n",
      "F1 score:  0.8476699770817417\n",
      "Accuracy score:  0.9984330354476615\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "clf.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:43:13] WARNING: /Users/travis/build/dmlc/xgboost/src/gbm/gbtree.cc:139: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "Precision:  0.9084310441094361\n",
      "Recall:  0.8645058448459086\n",
      "ROC score:  0.9319936330655176\n",
      "F1 score:  0.8859243125510482\n",
      "Accuracy score:  0.9986829325026483\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = ros.fit_resample(train_X, train_y)\n",
    "\n",
    "clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "clf.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:36:30] WARNING: /Users/travis/build/dmlc/xgboost/src/gbm/gbtree.cc:139: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "Precision:  0.8836702954898912\n",
      "Recall:  0.7547821466524973\n",
      "ROC score:  0.8770954202174641\n",
      "F1 score:  0.8141567559822324\n",
      "Accuracy score:  0.997961531570328\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smotetomek = SMOTETomek(random_state=42)\n",
    "\n",
    "train_X_resampled, train_y_resampled = smotetomek.fit_resample(train_X, train_y)\n",
    "\n",
    "clf = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "clf.fit(train_X_resampled, np.ravel(train_y_resampled))\n",
    "\n",
    "preds = pd.DataFrame(clf.predict(valid_X), columns=['predictions'])\n",
    "\n",
    "prec = precision_score(valid_y, preds)\n",
    "reca = recall_score(valid_y, preds)\n",
    "roc = roc_auc_score(valid_y, preds)\n",
    "f1 = f1_score(valid_y, preds)\n",
    "acc = accuracy_score(valid_y, preds)\n",
    "conf_mat = confusion_matrix(valid_y, preds)\n",
    "\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", reca)\n",
    "print(\"ROC score: \", roc)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
